{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.contingency import association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Merge Data - basic - remove nan / duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the data for df_final_demo\n",
    "pd.set_option('display.max_columns', 120) \n",
    "\n",
    "df_final_demo = pd.read_csv('../Data/Cleaned/df_final_demo (1).txt')\n",
    "\n",
    "# check for missing values\n",
    "df_final_demo[df_final_demo.isnull().any(axis=1)]\n",
    "\n",
    "# remove the missing values\n",
    "df_final_demo = df_final_demo.dropna()\n",
    "\n",
    "# remove gendr value X\n",
    "df_final_demo = df_final_demo[df_final_demo['gendr'] != 'X']\n",
    "df_final_demo['gendr'].value_counts()\n",
    "\n",
    "df_final_demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data for df_final_web_data\n",
    "\n",
    "df_web_data1 = pd.read_csv('../Data/Cleaned/df_final_web_data_pt_1.txt')\n",
    "df_web_data2 = pd.read_csv('../Data/Cleaned/df_final_web_data_pt_2.txt')\n",
    "df_final_experiment = pd.read_csv('../Data/Cleaned/df_final_experiment_clients.txt')\n",
    "\n",
    "# merge the data\n",
    "df_web_data = pd.concat([df_web_data1, df_web_data2])\n",
    "\n",
    "# check the duplicate\n",
    "df_web_data.duplicated().sum()\n",
    "\n",
    "# remove the duplicate\n",
    "df_web_data = df_web_data.drop_duplicates()\n",
    "\n",
    "#remove nan values for df_final_experiment\n",
    "df_final_experiment = df_final_experiment.dropna()\n",
    "\n",
    "#merge df_web_data and df_final_experiment\n",
    "df_web_data = pd.merge(df_web_data, df_final_experiment, on='client_id', how='inner')\n",
    "\n",
    "df_web_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the data\n",
    "df = pd.merge(df_web_data,df_final_demo, on='client_id', how='left')\n",
    "\n",
    "# make all columns lowercase\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the dataframe df, the numerical variables are:\n",
    "\n",
    "clnt_tenure_yr - discrete variables\n",
    "\n",
    "clnt_tenure_mnth  - discrete variables\n",
    "\n",
    "clnt_age - discrete variables\n",
    "\n",
    "num_accts - discrete variables\n",
    "\n",
    "calls_6_mnth - discrete variables\n",
    "\n",
    "logons_6_mnth - discrete variables\n",
    "\n",
    "\n",
    "bal - continuous variable \n",
    "\n",
    "\n",
    "#### The categorical variables are:\n",
    "\n",
    "variation - nominal variable\n",
    "\n",
    "gendr - ordinal variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA about demo dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who are the primary clients using this online process?\n",
    "Are the primary clients younger or older, new or long-standing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_plot = df['num_accts'].value_counts() \\\n",
    "    .head(10) \\\n",
    "    .plot(kind='bar', figsize=(10, 6), color='skyblue', fontsize=13, rot=45, title='Top 10 Number of Accounts')\n",
    "account_plot.set_xlabel('Top 10 Number of Accounts')\n",
    "account_plot.set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clnt_tenure_yr'].plot(kind='hist', bins=20, color='skyblue', figsize=(10, 6), fontsize=13, title='Client Tenure in Years')\n",
    "plt.xlabel('Client Tenure in Years')\n",
    "plt.ylabel('Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clnt_tenure_yr'].plot(kind='kde', color='skyblue', figsize=(10, 6), fontsize=13, title='Client Tenure in Years')\n",
    "plt.xlabel('Client Tenure in Years')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for the demographic data\n",
    "df_demo = df[['client_id', 'date_time', 'variation', 'clnt_tenure_yr', 'clnt_tenure_mnth', 'clnt_age', 'gendr', 'num_accts', 'bal', 'calls_6_mnth', 'logons_6_mnth']]\n",
    "df_demo.head(5)\n",
    "\n",
    "# create two dataframes based on the variation\n",
    "df_control = df_demo[df_demo['variation'] == 'Control']\n",
    "df_test = df_demo[df_demo['variation'] == 'Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using stacked histogram to compare the difference between the two groups, for clnt_age and num_accts, and clin_tenure_yr, clnt_tenure_mnth\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "sns.histplot(df_control['clnt_age'], kde=True, ax=axes[0, 0], color='blue', alpha=0.5)\n",
    "sns.histplot(df_test['clnt_age'], kde=True, ax=axes[0, 0], color='Red', alpha=0.5)\n",
    "\n",
    "sns.histplot(df_control['num_accts'], kde=True, ax=axes[0, 1], color='blue', alpha=0.5)\n",
    "sns.histplot(df_test['num_accts'], kde=True, ax=axes[0, 1], color='red', alpha=0.5)\n",
    "\n",
    "sns.histplot(df_control['clnt_tenure_yr'], kde=True, ax=axes[1, 0], bins=20, color='blue', alpha=0.5)\n",
    "sns.histplot(df_test['clnt_tenure_yr'], kde=True, ax=axes[1, 0],bins=20, color='red', alpha=0.5)\n",
    "\n",
    "sns.histplot(df_control['clnt_tenure_mnth'], kde=True, ax=axes[1, 1],bins=20, color='blue', alpha=0.5)\n",
    "sns.histplot(df_test['clnt_tenure_mnth'], kde=True, ax=axes[1, 1],bins=20, color='red', alpha=0.5)\n",
    "             \n",
    "# add labels\n",
    "\n",
    "axes[0, 0].set_xlabel('Client Age')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Client Age Distribution by Variation')\n",
    "\n",
    "axes[0, 1].set_xlabel('Number of Accounts')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Number of Accounts Distribution by Variation')\n",
    "\n",
    "axes[1, 0].set_xlabel('Client Tenure in Years')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Client Tenure in Years Distribution by Variation')\n",
    "\n",
    "axes[1, 1].set_xlabel('Client Tenure in Months')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Client Tenure in Months Distribution by Variation')\n",
    "\n",
    "# add legend\n",
    "\n",
    "axes[0, 0].legend(['Control', 'Test'])\n",
    "axes[0, 1].legend(['Control', 'Test'])\n",
    "axes[1, 0].legend(['Control', 'Test'])\n",
    "axes[1, 1].legend(['Control', 'Test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='clnt_age', y='num_accts', figsize=(10, 6), color='skyblue', fontsize=13, title='Client Age vs Number of Accounts')\n",
    "plt.xlabel('Client Age')\n",
    "plt.ylabel('Number of Accounts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.pairplot(df, \n",
    "             vars=['clnt_age', 'num_accts', 'clnt_tenure_yr', 'bal', 'calls_6_mnth', 'logons_6_mnth'], \n",
    "             diag_kind='kde', plot_kws={'color':'skyblue', 'alpha':0.5}, \n",
    "             diag_kws={'color':'skyblue', 'alpha':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use catplot to show the age distribution by variation\n",
    "sns.catplot(x='gendr', y='clnt_age', hue='variation', data=df, kind='box', height=6, aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIENT Gender AND VARIANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grouped bar chart to compare gender distribution by variation\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette='viridis')\n",
    "sns.catplot(x='gendr', kind='count', hue='variation', data=df_demo, height=5, aspect=2)\n",
    "\n",
    "# add labels\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "# make visual tight\n",
    "plt.tight_layout()\n",
    "\n",
    "# add title\n",
    "plt.title('The Gender Distribution by Variation')\n",
    "\n",
    "# add legend\n",
    "plt.legend(title='Variation', loc='upper right', labels=['Control', 'Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cross tab for the gender and variation\n",
    "gendr_variation = pd.crosstab(df_demo['gendr'], df_demo['variation'])\n",
    "\n",
    "# compute the probability of the age and variation\n",
    "gendr_variation['prob_control'] = gendr_variation['Control'] / gendr_variation['Control'].sum()\n",
    "gendr_variation['prob_test'] = gendr_variation['Test'] / gendr_variation['Test'].sum()\n",
    "\n",
    "# use chi-square test to determine if the age and variation are independent\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, dof, ex = chi2_contingency(gendr_variation[['Control', 'Test']])\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the result\n",
    "if p < 0.05:\n",
    "    print('There is a significant difference between the gender and variation')\n",
    "else:\n",
    "    print('There is no significant difference between the gender and variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls_6_mnth: Records the number of times the client reached out over a call in the past six months.\n",
    "# logons_6_mnth: Reflects the frequency with which the client logged onto Vanguard’s platform over the last six months.\n",
    "\n",
    "#using displot to compare the difference between the two groups, for calls_6_mnth and logons_6_mnth\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "sns.histplot(df_control['calls_6_mnth'], kde=True, ax=axes[0], color='blue', alpha=0.5)\n",
    "sns.histplot(df_test['calls_6_mnth'], kde=True, ax=axes[0], color='red', alpha=0.5)\n",
    "\n",
    "sns.histplot(df_control['logons_6_mnth'], kde=True, ax=axes[1], color='blue', alpha=0.5)\n",
    "sns.histplot(df_test['logons_6_mnth'], kde=True, ax=axes[1], color='red', alpha=0.5)\n",
    "\n",
    "# add labels\n",
    "axes[0].set_xlabel('Number of Calls in the Last 6 Months')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Number of Calls in the Last 6 Months Distribution by Variation')\n",
    "\n",
    "axes[1].set_xlabel('Number of Logons in the Last 6 Months')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Number of Logons in the Last 6 Months Distribution by Variation')\n",
    "\n",
    "# add legend\n",
    "axes[0].legend(['Control', 'Test'])\n",
    "axes[1].legend(['Control', 'Test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart to show the distribution of the variation\n",
    "plt.figure(figsize=(10, 7))\n",
    "df_demo['variation'].value_counts(dropna=False).plot.pie(autopct='%1.1f%%',colors=['#FFA07A', '#20B2AA', '#87CEFA'])\n",
    "plt.title('Variation Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the correlation between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_numerical = df_demo[['clnt_tenure_yr', 'clnt_age', 'num_accts', 'bal', 'calls_6_mnth', 'logons_6_mnth']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use heatmap to show the correlation between the numerical variables, clnt_tenure_yr, clnt_tenure_mnth, clnt_age, num_accts, bal, calls_6_mnth, logons_6_mnth\n",
    "\n",
    "\n",
    "sns.heatmap(cor_numerical, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# add labels\n",
    "plt.xlabel('Numerical Variables')\n",
    "plt.ylabel('Numerical Variables')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the result\n",
    "The heatmap shows that there is a strong correlation between the number of accounts and the balance.\n",
    "\n",
    "There is also a moderate correlation between the number of calls in the last 6 months and the number of logons in the last 6 months.\n",
    "\n",
    "\n",
    "The heatmap shows the correlation between the numerical variables. The correlation ranges from -1 to 1.\n",
    "\n",
    "\n",
    "A correlation of 1 indicates a perfect positive correlation, while a correlation of -1 indicates a perfect negative correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo['num_accts'].unique()\n",
    "\n",
    "df_demo.isnull().sum()\n",
    "\n",
    "# Remove rows with NaN values\n",
    "df_demo_clean = df_demo.dropna()\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "corr, p = pearsonr(df_demo_clean['num_accts'], df_demo_clean['bal'])\n",
    "corr, p\n",
    "\n",
    "# explain the pearson value\n",
    "if corr > 0.5:\n",
    "    print('The correlation between the number of accounts and balance is strong')\n",
    "elif corr > 0.3:\n",
    "    print('The correlation between the number of accounts and balance is moderate')\n",
    "else:\n",
    "    print('The correlation between the number of accounts and balance is weak')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use QQ plot to check the normality of the num_accts and bal\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sm.qqplot(df_demo['num_accts'], line='s')\n",
    "plt.title('QQ Plot - num_accts')\n",
    "plt.show()\n",
    "\n",
    "# QQ plot for bal\n",
    "sm.qqplot(df['bal'], line='s')\n",
    "plt.title('QQ Plot - bal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caculate the completion rate by counting how many confirm by client_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The defination of completion rate:  When a client has reach to confirm step which is process_step is confrim, meaning the client has complete the process, only client only has one confirm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add a new column to show the number of steps\n",
    "df['num_steps'] = df['process_step'].map({'start':0, 'step_1':1, 'step_2':2, 'step_3':3, 'confirm':4})\n",
    "\n",
    "# df sorted by client_id and date\n",
    "df = df.sort_values(by=['client_id', 'date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of steps for each client\n",
    "df_count_step = df.groupby(['client_id', 'num_steps']).size().unstack(fill_value=0)\n",
    "# merge the data with the demographic data\n",
    "df_num_steps = pd.merge(df_count_step, df_final_experiment, on='client_id', how='left')\n",
    "\n",
    "\n",
    "# if a client_id, cloumn 4 value >=1 then the client has completed the process\n",
    "df_num_steps['completed'] = df_num_steps[4] >= 1\n",
    "df_num_steps['completed'].value_counts()\n",
    "\n",
    "# calculate the percentage of clients who completed the process\n",
    "completed_clients = df_num_steps[df_num_steps['completed'] == True]\n",
    "not_completed_clients = df_num_steps[df_num_steps['completed'] == False]\n",
    "\n",
    "# calculate the percentage of clients who completed the process \n",
    "completed_percentage = (completed_clients['client_id'].nunique() / df['client_id'].nunique()) * 100\n",
    "\n",
    "# calculate the percentage of clients who did not complete the process\n",
    "not_completed_percentage = (not_completed_clients['client_id'].nunique() / df['client_id'].nunique()) * 100\n",
    "\n",
    "completed_percentage, not_completed_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using grouped bar chart to completed precentage by variation\n",
    "sns.set_theme(style=\"whitegrid\", palette='viridis')\n",
    "sns.catplot(x='completed', kind='count', hue='Variation', data=df_num_steps, height=5, aspect=2)\n",
    "\n",
    "# add labels\n",
    "plt.xlabel('Completed')\n",
    "plt.ylabel('Count')\n",
    "# make visual tight\n",
    "plt.tight_layout()\n",
    "\n",
    "# add title\n",
    "plt.title('The Completed Percentage by Variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cross tab for the completed and variation\n",
    "completed_variation = pd.crosstab(df_num_steps['completed'], df_num_steps['Variation'])\n",
    "# add proportion of the completed and variation\n",
    "completed_variation['prob_control'] = completed_variation['Control'] / completed_variation['Control'].sum()\n",
    "completed_variation['prob_test'] = completed_variation['Test'] / completed_variation['Test'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_variation\n",
    "\n",
    "# make pie charts to compare the percentage of clients who completed the process by control and test group\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "completed_variation['Control'].plot.pie(autopct='%1.1f%%', ax=axes[0], colors=['#FFA07A', '#20B2AA', '#87CEFA'])\n",
    "axes[0].set_title('Percentage of Clients Who Completed the Process in the Control Group')\n",
    "\n",
    "completed_variation['Test'].plot.pie(autopct='%1.1f%%', ax=axes[1], colors=['#FFA07A', '#20B2AA', '#87CEFA'])\n",
    "axes[1].set_title('Percentage of Clients Who Completed the Process in the Test Group')\n",
    "\n",
    "# add legend\n",
    "axes[0].legend(['Control', 'Test'])\n",
    "axes[1].legend(['Control', 'Test'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD THE TIME SPEND ON EACH STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# organzie the data by date_time\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "#calculate the time difference by client_id\n",
    "df['time_diff'] = np.where(df['visit_id'] != df['visit_id'].shift(1), 0, df.sort_values(['client_id', 'date_time']).groupby('client_id')['date_time'].diff().dt.total_seconds().fillna(0))\n",
    "\n",
    "# add time spend column which is time_diff move up by one row\n",
    "df['time_spend'] = df.groupby([\"visit_id\"])['time_diff'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 120)\n",
    "# df[df['client_id'] == 3825423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each client the average time spend on each step by variation\n",
    "df_web_data_grouped_client = df.groupby(['variation', 'client_id', 'num_steps'])['time_spend'].mean().reset_index()\n",
    "df_web_data_grouped_client\n",
    "\n",
    "# using seaborn catplot to create a grouped bar chart\n",
    "sns.catplot(x='num_steps', y='time_spend', hue='variation', data=df_web_data_grouped, kind='bar', height=6, aspect=2, palette = 'viridis')\n",
    "plt.title('Time Spend on Each Step by Variation')\n",
    "plt.xticks([0, 1, 2,3, 4], ['start','step 1', 'step 2', 'step 3', 'confirm'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average time spend on each step by variation\n",
    "df_web_data_grouped = df.groupby(['variation', 'num_steps'])['time_spend'].mean().reset_index()\n",
    "df_web_data_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the error column to the data\n",
    "df['error'] = np.where((df['visit_id'] == df['visit_id'].shift(1)) & (df['num_steps'] <= df['num_steps'].shift(1)), 'error', 'nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking this id and sort it by date_time \n",
    "# df[df['client_id'] == 8290360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 120)\n",
    " # df[df['client_id'] == 1336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a countplot of the error column by variation\n",
    "sns.countplot(x='error', data=df, hue='variation', palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show error by num_steps and variation\n",
    "df_web_data_error = df[df['error'] == 'error']\n",
    "df_web_data_error_grouped = df_web_data_error.groupby(['variation', 'num_steps'])['error'].count().reset_index()\n",
    "df_web_data_error_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using seaborn catplot to create a grouped bar chart\n",
    "sns.catplot(x='num_steps', y='error', hue='variation', data=df_web_data_error_grouped, kind='bar', height=6, aspect=2, palette = 'viridis')\n",
    "plt.title('Error by Step and Variation')\n",
    "plt.xticks([0, 1, 2,3, 4], ['start','step 1', 'step 2', 'step 3', 'confirm'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data and KPIs you have explored discussed, one interesting hypothesis to test is related to the completion rate between the Test and Control groups. \n",
    "\n",
    "Since the new design (Test group) had a higher completion rate compared to the old design (Control group), you are required to confirm if this difference is statistically significant.\n",
    "\n",
    "Make sure to define the proper null and an alternative hypothesis to test it. \n",
    "\n",
    "Use the provided data to test these hypotheses, and determine if you can reject the null hypothesis in favor of the alternative. \n",
    "\n",
    "Make sure to consider the significance level, p-value, the statistical test prerequisites, and other relevant statistical measures in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_num_steps[df_num_steps[\"Variation\"]==\"Test\"][\"completed\"]\n",
    "df_control = df_num_steps[df_num_steps[\"Variation\"]==\"Control\"][\"completed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the hypothesis\n",
    "\n",
    "#H0: Test Group completion rate <= Control Group completion rate\n",
    "#H1: Test Group completion rate > Control\n",
    "\n",
    "#significance level = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "st.ttest_ind(df_test,df_control, equal_var='less')\n",
    "t_stat, p_value = st.ttest_ind(df_test, df_control, equal_var=False)\n",
    "t_stat, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because p_value is lower than significance level, we reject the null hypothesis, that means Test Group Completion rate is higher than Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The introduction of a new UI design comes with its associated costs: design, development, testing, potential training for staff, and possible short-term disruptions or adjustments for users. To justify these costs, Vanguard has determined that any new design should lead to a minimum increase in the completion rate to be deemed cost-effective.\n",
    "\n",
    "Threshold: Vanguard has set this minimum increase in completion rate at 5%. This is the rate at which the projected benefits, in terms of increased user engagement and potential revenue, are estimated to outweigh the costs of the new design.\n",
    "\n",
    "You are required to carry out another analysis, ensuring that the observed increase in completion rate from the A/B test meets or exceeds this 5% threshold. If the new design doesn’t lead to at least this level of improvement, it may not be justifiable from a cost perspective, regardless of its statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A/B testing to compare the completion rate between the control and test group \n",
    "\n",
    "# set the hypothesis\n",
    "# H0: Test Group completion rate <= Control Group completion rate  = 0.05\n",
    "# H1: Test Group completion rate > Control Group completion rate   = 0.05\n",
    "\n",
    "# significance level = 0.05\n",
    "import scipy.stats as st\n",
    "\n",
    "# calculate the completion rate for the control and test group\n",
    "control_completion_rate = df_num_steps[df_num_steps['Variation'] == 'Control']['completed'].mean()\n",
    "test_completion_rate = df_num_steps[df_num_steps['Variation'] == 'Test']['completed'].mean()\n",
    "\n",
    "# calculate the completion rate difference\n",
    "completion_rate_diff = test_completion_rate - control_completion_rate\n",
    "\n",
    "# calculate the standard deviation for the control and test group\n",
    "control_std = df_num_steps[df_num_steps['Variation'] == 'Control']['completed'].std()\n",
    "test_std = df_num_steps[df_num_steps['Variation'] == 'Test']['completed'].std()\n",
    "\n",
    "# calculate the standard error\n",
    "control_se = control_std / np.sqrt(df_num_steps[df_num_steps['Variation'] == 'Control']['completed'].count())\n",
    "test_se = test_std / np.sqrt(df_num_steps[df_num_steps['Variation'] == 'Test']['completed'].count())\n",
    "\n",
    "# calculate the t-statistic\n",
    "t_stat = (test_completion_rate - control_completion_rate) / np.sqrt(control_se**2 + test_se**2)\n",
    "t_stat\n",
    "\n",
    "# calculate the degrees of freedom\n",
    "df1 = df_num_steps[df_num_steps['Variation'] == 'Control']['completed'].count() + df_num_steps[df_num_steps['Variation'] == 'Test']['completed'].count() - 2\n",
    "\n",
    "# calculate the p-value\n",
    "p_value = 1 - st.t.cdf(t_stat, df1)\n",
    "p_value\n",
    "\n",
    "# explain the result\n",
    "if p_value < 0.05:\n",
    "    print('There is a significant difference between the completion rate of the control and test group')\n",
    "else:\n",
    "    print('There is no significant difference between the completion rate of the control and test group')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_completion_rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design Effectiveness\n",
    "Was the experiment well-structured?\n",
    "\n",
    "Were clients randomly and equally divided between the old and new designs?\n",
    "\n",
    "Were there any biases?\n",
    "\n",
    "Duration Assessment\n",
    "Was the timeframe of the experiment (from 3/15/2017 to 6/20/2017) adequate to gather meaningful data and insights?\n",
    "\n",
    "Additional Data Needs\n",
    "What other data, if available, could enhance the analysis?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a date range for the data, start date os 3/15/2017 and end date is 6/20/2017\n",
    "\n",
    "start_date = '2017-03-15'\n",
    "end_date = '2017-06-20'\n",
    "\n",
    "# only select the data within the date range\n",
    "df_date = df[(df['date_time'] >= start_date) & (df['date_time'] <= end_date)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
